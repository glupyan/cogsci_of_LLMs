<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Cognitive Science of Large Language Models on Psych 711: Cognitive Science of Large Language Models. Fall, 2025</title>
    <link>/</link>
    <description>Recent content in Cognitive Science of Large Language Models on Psych 711: Cognitive Science of Large Language Models. Fall, 2025</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 26 Aug 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Logistics</title>
      <link>/logistics/</link>
      <pubDate>Tue, 26 Aug 2025 00:00:00 +0000</pubDate>
      <guid>/logistics/</guid>
      <description>Course: Psych 711: Cognitive Science of Large Language Models&#xA;Instructor: Prof. Gary Lupyan. Email. Lab&#xA;Class Hours: Wednesdays 9:00am-11:30am, Brogden 338&#xA;Office hours: Mondays 1pm-2pm, Brogden 526&#xA;Where to access the readings I&amp;rsquo;ve uploaded all the readings to Google Drive. Feel free to download the whole thing to a local folder. If there are changes to the syllabus, the Google Drive folder will be automatically updated.&#xA;Where to submit what Submit essays, reading responses, and final projects using the class canvas site</description>
    </item>
    <item>
      <title>Resources</title>
      <link>/resources/</link>
      <pubDate>Tue, 26 Aug 2025 00:00:00 +0000</pubDate>
      <guid>/resources/</guid>
      <description>Blogdown book: https://bookdown.org/yihui/blogdown/ Hugo: https://gohugo.io/ Netlify docs: https://docs.netlify.com/ Add additional course-specific tools here.</description>
    </item>
    <item>
      <title></title>
      <link>/schedule/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/schedule/</guid>
      <description>Class Schedule1 I recommend reading the papers in the order in which they are listed.&#xA;Wednesday, September 3, 2025 What is learnable? Readings (in class): Sutton (2019); Aguera y Arcas (2025); Related resources: Halevy et al. (2009); talk by Alyosha Efros Wednesday, September 10, 2025 How do LLMs work? Readings: Rumelhart (1989); Lee (2025); Either Vaswani et al. (2017) or Phuong &amp;amp; Hutter (2022) . Other resources for understanding transformers (very useful; strongly recommended!</description>
    </item>
    <item>
      <title></title>
      <link>/schedule_bib/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/schedule_bib/</guid>
      <description>Class Schedule1 I recommend reading the papers in the order in which they are listed.&#xA;r advdate(wed, 1) What is learnable? Readings (in class): @suttonBitterLesson2019; @WhatIntelligenceAntikythera; Related resources: @halevyUnreasonableEffectivenessData2009; talk by Alyosha Efros r advdate(wed, 2) How do LLMs work? Readings: @rumelhartArchitectureMindConnectionist1989; @leeLargeLanguageModels2025; Either @vaswaniAttentionAllYou2023 or @phuongFormalAlgorithmsTransformers2022 . Other resources for understanding transformers (very useful; strongly recommended!): The illustrated transformer; Transformers, the tech behind LLMs video and the next chapter focusing on attention; Extra: @mccoyEmbersAutoregressionShow2024 r advdate(wed, 3) Learning language from language Special guest - Steven Piantadosi</description>
    </item>
  </channel>
</rss>
