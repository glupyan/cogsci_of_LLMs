
# Class Schedule[^:1]

I recommend reading the papers in the order in which they are listed.

[^:1]: Subject to revision

# `r advdate(wed, 1)`

### What is learnable?

* **Readings (in class):** @suttonBitterLesson2019; @WhatIntelligenceAntikythera; 
* *Related resources*: @halevyUnreasonableEffectivenessData2009; [talk by Alyosha Efros](youtube.com/watch?v=R7qy2BY6mTk&list=PL2xTeGtUb-8B94jdWGT-chu4ucI7oEe_x&index=32&pp=iAQB)


# `r advdate(wed, 2)`

### How do LLMs work?

* **Readings:** @rumelhartArchitectureMindConnectionist1989; @leeLargeLanguageModels2025; Either @vaswaniAttentionAllYou2023 or @phuongFormalAlgorithmsTransformers2022 . 
* **Other resources for understanding transformers (very useful; strongly recommended!)**: 
[The illustrated transformer](https://jalammar.github.io/illustrated-transformer/?utm_source=chatgpt.com); [Transformers, the tech behind LLMs video](https://www.youtube.com/watch?v=wjZofJX0v4M&ab_channel=3Blue1Brown) and the [next chapter focusing on attention](https://www.youtube.com/watch?v=eMlx5fFNoYc&ab_channel=3Blue1Brown); 
* Extra: @mccoyEmbersAutoregressionShow2024

# `r advdate(wed, 3)`

### Learning language from language

**Special guest** - Steven Piantadosi

* **Readings:** @elman_finding_1990; @boleda_distributional_2020; @piantadosiModernLanguageModels2024 

# `r advdate(wed, 4)`

### Learning about the world from language 

**Special guest** - Marina Bedny

* **Readings:** [Plato: The allegory of the cave](https://scholar.harvard.edu/files/seyer/files/plato_republic_514b-518d_allegory-of-the-cave.pdf); @lupyan_words-as-mappings_2017; @yildirimTaskStructuresWorld2024; @wangConstructingMeaningLanguageforthcoming

* Recommended: response to Yildirim and& Paul: @godduLLMsDontKnow2024; Counter-response: @yildirimResponseGodduNew2024

# `r advdate(wed, 5)` 

### Do large language models understand us?

* **Readings:** @mitchell_debate_2023; @aguerayarcasLargeLanguageModels2022; @piantadosi_meaning_2022
* **Short reflection essay**: So what do you think? Do large language models understand us? (~800 words).
* Extra: Feel free to also browse the talks in [this series organized by Stevan Harnad](https://skywritingspress.ca/), e.g., the [different kinds of understanding by Chalmers](https://www.youtube.com/watch?v=yyRzTL201zI&list=PL2xTeGtUb-8B94jdWGT-chu4ucI7oEe_x&index=24&pp=iAQB). 

# `r advdate(wed, 6)` 

### Stress testing embodiment
* Lots of reading this week! 
* **Readings:** @barsalou_perceptual_1999; @mollo_vector_2023; @chalmersDoesThoughtRequire2024;
@pavlickSymbolsGroundingLarge2023
* Extra: [A phliosophical take by David Chalmers on the possibility of "pure thinkers"](https://philpapers.org/archive/CHADTR.pdf)

# `r advdate(wed, 7)` 

### Stress testing the language of thought hypothesis: learning to learn and represent

* **Readings:** @quilty-dunn_best_2022 (also read at least 2 positive and 2 negative commentaries); @lakeHumanlikeSystematicGeneralization2023; Watch [this talk on learning compositionality by Pavlick](https://www.youtube.com/watch?v=6gSYMX3I5Bs&ab_channel=KempnerInstituteatHarvardUniversity)
* Extra: @griffithsWhitherSymbolsEra2025; @binzMetalearnedModelsCognition2024; 

# `r advdate(wed, 8)` 

### Stress testing numerical cognition

* **Readings:** @leslie2008generative; @banerjeeChildrensArithmeticSkills2025; @oshaughnessyDiverseMathematicalKnowledge2023; @nandaProgressMeasuresGrokking2023 (don't worry about all the technical details. Focus on the big picture. The authors do have a useful [video walkthrough](https://www.youtube.com/watch?v=IHikLL8ULa4&ab_channel=NeelNanda)).
* Extra: @gordon_numerical_2004; @oshaughnessy2019cultural; 

# `r advdate(wed, 9)` 

### Stress testing concepts: representational format; flexibility; data efficiency

* **Readings:** *Tentative:* @casasanto_all_2014; @barsalou_staying_2016; 
* *Related resources*: This ~2010 talk by Efros on the [role of categories in recognition](https://www.youtube.com/watch?v=Qrl7WJLoMDk&ab_channel=MicrosoftResearch), 

# `r advdate(wed, 10)` 

### Stress testing reasoning: the role of context

* **Readings:** *(Tentative)* @evans_dual-processing_2008; @lampinenLanguageModelsHumans2024

# `r advdate(wed, 11)` 

### Stress testing theories of intelligence

* **Readings:** TBA: @leggCollectionDefinitionsIntelligence2007; @cholletMeasureIntelligence2019; Chapter 12 of Aguera y Arcas's _What is Intelligence_.

* Extras: @van_der_maas_dynamical_2006; @leggUniversalIntelligenceDefinition2007; @szathmary_major_1995

# `r advdate(wed, 12)` 

### Stress testing methodology of cognitive psychology/cognitive (neuro)science

* **Readings:** 
@bowerExperimentalMethodsCognitive1989 (read or skim depending on your level of familiarity); @jonasCouldNeuroscientistUnderstand2017; Read 2 of the 12 case studies from @lindsey+BiologyLargeLanguage
* Extras: @nickelsSingleCaseStudies2022; @yarkoniGeneralizabilityCrisis2020

# `r advdate(wed, 13)` 

### Thanksgiving - no class

* **Project proposals due** by 8pm.

# `r advdate(wed, 14)` 

### Revisiting old and new questions

* **Readings:** Review previous readings in light of what you've learned
* **Short reflection essay**: Is all the AI madness of the last few years good for or bad for understanding the human mind? (~800 words).

# `r advdate(wed, 15)` 

### Final presentations

### Group project presentations [20 min presentation + 8 min Q&A].
